
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>nengolib.learning.RLS &#8212; nengolib 0.5.1 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '0.5.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="_static/logo.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="nengolib.neurons.init_lif" href="nengolib.neurons.init_lif.html" />
    <link rel="prev" title="nengolib.Connection" href="nengolib.Connection.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="nengolib-learning-rls">
<h1>nengolib.learning.RLS<a class="headerlink" href="#nengolib-learning-rls" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="nengolib.learning.RLS">
<em class="property">class </em><code class="descclassname">nengolib.learning.</code><code class="descname">RLS</code><span class="sig-paren">(</span><em>learning_rate=1.0</em>, <em>pre_synapse=Lowpass(0.005)</em><span class="sig-paren">)</span><a class="reference external" href="https://github.com/arvoelke/nengolib/tree/v0.5.1/nengolib/learning.py#L12-L145"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nengolib.learning.RLS" title="Permalink to this definition">¶</a></dt>
<dd><p>Recursive least-squares rule for online decoder optimization.</p>
<p>This may be used to learn the weights on a <a class="reference external" href="https://www.nengo.ai/nengo/frontend_api.html#nengo.Connection" title="(in Nengo v3.0)"><code class="xref py py-class docutils literal"><span class="pre">nengo.Connection</span></code></a>,
online, in an L2-optimal manner. To be applied in the same scenarios as
<a class="reference external" href="https://www.nengo.ai/nengo/frontend_api.html#nengo.PES" title="(in Nengo v3.0)"><code class="xref py py-class docutils literal"><span class="pre">nengo.PES</span></code></a>, to minimize some error signal.</p>
<p>In the end, the only real difference between RLS learning and using the
<a class="reference external" href="https://www.nengo.ai/nengo/frontend_api.html#nengo.solvers.LstsqL2" title="(in Nengo v3.0)"><code class="xref py py-class docutils literal"><span class="pre">nengo.solvers.LstsqL2</span></code></a> solver, is <em>when</em> the learning takes
place. In the former case, the weights are learned online from an error
signal over time, whereas in the latter case, the weights are learned
offline in a batch optimization from the provided training data
(<code class="docutils literal"><span class="pre">eval_points</span></code> and <code class="docutils literal"><span class="pre">function</span></code>).</p>
<p>The cost of RLS is <span class="math">\(\mathcal{O}\left(n^2\right)\)</span> extra
time and memory. It is typically much more efficient to do the learning
offline using the <a class="reference external" href="https://www.nengo.ai/nengo/frontend_api.html#nengo.solvers.LstsqL2" title="(in Nengo v3.0)"><code class="xref py py-class docutils literal"><span class="pre">nengo.solvers.LstsqL2</span></code></a> solver.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>learning_rate</strong> <span class="classifier-delimiter">:</span> <span class="classifier"><code class="docutils literal"><span class="pre">float</span></code>, optional</span></dt>
<dd><p class="first last">Effective learning rate. This is better understood as
<span class="math">\(\frac{1}{\alpha}\)</span>, where <span class="math">\(\alpha\)</span> is an
L2-regularization term. A large learning rate means little
regularization, which implies quick over-fitting. A small learning
rate means large regularization, which translates to slower
learning. Defaults to 1.0. <a class="footnote-reference" href="#id2" id="id1">[1]</a></p>
</dd>
<dt><strong>pre_synapse</strong> <span class="classifier-delimiter">:</span> <span class="classifier"><a class="reference external" href="https://www.nengo.ai/nengo/frontend_api.html#nengo.synapses.Synapse" title="(in Nengo v3.0)"><code class="xref py py-class docutils literal"><span class="pre">nengo.synapses.Synapse</span></code></a>, optional</span></dt>
<dd><p class="first last">Filter applied to the pre-synaptic neural activities, for the
purpose of applying the weight update.
Defaults to a <a class="reference external" href="https://www.nengo.ai/nengo/frontend_api.html#nengo.Lowpass" title="(in Nengo v3.0)"><code class="xref py py-class docutils literal"><span class="pre">nengo.Lowpass</span></code></a> filter with a time-constant of
5 ms.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<p class="last"><a class="reference external" href="https://www.nengo.ai/nengo/frontend_api.html#nengo.PES" title="(in Nengo v3.0)"><code class="xref py py-class docutils literal"><span class="pre">nengo.PES</span></code></a>, <a class="reference external" href="https://www.nengo.ai/nengo/frontend_api.html#nengo.solvers.LstsqL2" title="(in Nengo v3.0)"><code class="xref py py-class docutils literal"><span class="pre">nengo.solvers.LstsqL2</span></code></a>, <a class="reference internal" href="nengolib.solvers.Temporal.html#nengolib.solvers.Temporal" title="nengolib.solvers.Temporal"><code class="xref py py-class docutils literal"><span class="pre">Temporal</span></code></a></p>
</div>
<p class="rubric">Notes</p>
<p>RLS works by maintaining the inverse neural correlation matrix,
<span class="math">\(\Gamma^{-1}\)</span>, where <span class="math">\(\Gamma = A^T A + \alpha I\)</span> are the
regularized correlations, <span class="math">\(A\)</span> is a matrix of (possibly filtered)
neural activities, and <span class="math">\(\alpha\)</span> is an L2-regularization term
controlled by the <code class="docutils literal"><span class="pre">learning_rate</span></code>. This matrix is used to project the
error signal and update the weights to be L2-optimal, at each time-step.</p>
<p>The time-step does not play a role in this learning rule, apart from
determining the time-scale over which the <code class="docutils literal"><span class="pre">pre_synapse</span></code> is discretized.
A complete learning update is applied on every time-step.</p>
<p>Attributes that can be probed from this learning rule:
<code class="docutils literal"><span class="pre">pre_filtered</span></code>, <code class="docutils literal"><span class="pre">error</span></code>, <code class="docutils literal"><span class="pre">delta</span></code>, <code class="docutils literal"><span class="pre">inv_gamma</span></code>.</p>
<p class="rubric">References</p>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>Sussillo, D., &amp; Abbott, L. F. (2009). Generating coherent patterns
of activity from chaotic neural networks. Neuron, 63(4), 544-557.</td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<p>See <a class="reference internal" href="notebooks/examples/full_force_learning.html"><span class="doc">full-FORCE and “Classic FORCE” learning with spikes</span></a> for an example of how to
use RLS to learn spiking FORCE <a class="footnote-reference" href="#id2" id="id3">[1]</a> and “full-FORCE” networks in Nengo.</p>
<p>Below, we compare <a class="reference external" href="https://www.nengo.ai/nengo/frontend_api.html#nengo.PES" title="(in Nengo v3.0)"><code class="xref py py-class docutils literal"><span class="pre">nengo.PES</span></code></a> against <a class="reference internal" href="#nengolib.learning.RLS" title="nengolib.learning.RLS"><code class="xref py py-class docutils literal"><span class="pre">RLS</span></code></a>, learning a
feed-forward communication channel (identity function), online,
and starting with 100 spiking LIF neurons from scratch (zero weights).
A faster learning rate for <a class="reference external" href="https://www.nengo.ai/nengo/frontend_api.html#nengo.PES" title="(in Nengo v3.0)"><code class="xref py py-class docutils literal"><span class="pre">nengo.PES</span></code></a> results in over-fitting to
the most recent online example, while a slower learning rate does not
learn quickly enough. This is a general problem with greedy optimization.
<a class="reference internal" href="#nengolib.learning.RLS" title="nengolib.learning.RLS"><code class="xref py py-class docutils literal"><span class="pre">RLS</span></code></a> performs better since it is L2-optimal.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nengolib</span> <span class="k">import</span> <span class="n">RLS</span><span class="p">,</span> <span class="n">Network</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">nengo</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nengo</span> <span class="k">import</span> <span class="n">PES</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tau</span> <span class="o">=</span> <span class="mf">0.005</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">learning_rules</span> <span class="o">=</span> <span class="p">(</span><span class="n">PES</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">pre_tau</span><span class="o">=</span><span class="n">tau</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span>                  <span class="n">RLS</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">pre_synapse</span><span class="o">=</span><span class="n">tau</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">Network</span><span class="p">()</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">u</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">t</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">probes</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">for</span> <span class="n">lr</span> <span class="ow">in</span> <span class="n">learning_rules</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">e</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">size_in</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                       <span class="n">output</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="n">e</span> <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">x</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">y</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">size_in</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">conn</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">learning_rule_type</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>            <span class="n">function</span><span class="o">=</span><span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">conn</span><span class="o">.</span><span class="n">learning_rule</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="n">tau</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">probes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="n">tau</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">probes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="n">tau</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">sim</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">probes</span><span class="p">[</span><span class="mi">0</span><span class="p">]],</span>
<span class="gp">&gt;&gt;&gt; </span>         <span class="n">label</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">learning_rules</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">probes</span><span class="p">[</span><span class="mi">1</span><span class="p">]],</span>
<span class="gp">&gt;&gt;&gt; </span>         <span class="n">label</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span><span class="n">learning_rules</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">(),</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">probes</span><span class="p">[</span><span class="mi">2</span><span class="p">]],</span>
<span class="gp">&gt;&gt;&gt; </span>         <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ideal&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">vlines</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training -&gt; Testing&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time (s)&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>(<a class="reference external" href=".//nengolib-learning-RLS-1.py">Source code</a>)</p>
<div class="figure">
<img alt="_images/nengolib-learning-RLS-1.png" src="_images/nengolib-learning-RLS-1.png" />
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Attributes:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>learning_rate</strong></dt>
<dd><p class="first last">A parameter where the value is a number.</p>
</dd>
<dt><strong>pre_synapse</strong></dt>
<dd></dd>
<dt><strong>size_in</strong></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="index.html">
    <img class="logo" src="_static/logo.png" alt="Logo"/>
    
    <h1 class="logo logo-name">nengolib</h1>
    
  </a>
</p>



<p class="blurb">Tools for robust dynamics in Nengo.</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=arvoelke&repo=nengolib&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





    

<p>
<a class="badge" href="https://travis-ci.org/arvoelke/nengolib">
    <img
        alt="https://secure.travis-ci.org/arvoelke/nengolib.svg?branch=master"
        src="https://secure.travis-ci.org/arvoelke/nengolib.svg?branch=master"
    />
</a>
</p>




    

<p>
<a class="badge" href="https://codecov.io/github/arvoelke/nengolib">
    <img
    alt="https://codecov.io/github/arvoelke/nengolib/coverage.svg?branch=master"
    src="https://codecov.io/github/arvoelke/nengolib/coverage.svg?branch=master"
    />
</a>
</p>
<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="notebooks.html">Notebooks</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="reference.html">Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="nengolib.html">Main (<code class="docutils literal"><span class="pre">nengolib</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="nengolib.networks.html">Networks (<code class="docutils literal"><span class="pre">nengolib.networks</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="nengolib.signal.html">Signal (<code class="docutils literal"><span class="pre">nengolib.signal</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="nengolib.stats.html">Stats (<code class="docutils literal"><span class="pre">nengolib.stats</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="nengolib.synapses.html">Synapses (<code class="docutils literal"><span class="pre">nengolib.synapses</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="success.html">Success stories</a></li>
<li class="toctree-l1"><a class="reference internal" href="license.html">License</a></li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  <li><a href="reference.html">Reference</a><ul>
  <li><a href="nengolib.html">Main (<code class="docutils literal"><span class="pre">nengolib</span></code>)</a><ul>
      <li>Previous: <a href="nengolib.Connection.html" title="previous chapter">nengolib.Connection</a></li>
      <li>Next: <a href="nengolib.neurons.init_lif.html" title="next chapter">nengolib.neurons.init_lif</a></li>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017-2019, Aaron Voelker.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.7</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/nengolib.learning.RLS.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>