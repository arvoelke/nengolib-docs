
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>full-FORCE and “Classic FORCE” learning with spikes &#8212; nengolib 0.4.3-dev documentation</title>
    <link rel="stylesheet" href="../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.4.3-dev',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="shortcut icon" href="../../_static/logo.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Heterogeneous Synapses" href="hetero_synapse.html" />
    <link rel="prev" title="Examples" href="../../notebooks.examples.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head>
  <body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="full-FORCE-and-“Classic-FORCE”-learning-with-spikes">
<h1>full-FORCE and “Classic FORCE” learning with spikes<a class="headerlink" href="#full-FORCE-and-“Classic-FORCE”-learning-with-spikes" title="Permalink to this headline">¶</a></h1>
<p>This notebook demonstrates how to implement both full-FORCE [1] and “Classic FORCE” [2] networks in Nengo. This makes it “trivial” to switch between neuron models (rate-based, spiking, adaptive, etc.), and to explore the effects of different learning rules and architectural assumptions.</p>
<p>For this demonstration, we use recursive least-squares (RLS) learning, with spiking <code class="docutils literal"><span class="pre">LIF</span></code> neurons, and the two basic architectures (full-FORCE and classic-FORCE) – to learn a bandpass filter (a.k.a. a “decaying oscillator” triggered by unit impulses).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">pylab</span> inline
<span class="kn">import</span> <span class="nn">pylab</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>  <span class="c1"># optional; prettier graphs</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">nengo</span>
<span class="kn">import</span> <span class="nn">nengolib</span>
<span class="kn">from</span> <span class="nn">nengolib</span> <span class="k">import</span> <span class="n">RLS</span><span class="p">,</span> <span class="n">Network</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Populating the interactive namespace from numpy and matplotlib
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># Task parameters</span>
<span class="n">pulse_interval</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">amplitude</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">freq</span> <span class="o">=</span> <span class="mf">3.0</span>
<span class="n">decay</span> <span class="o">=</span> <span class="mf">2.0</span>
<span class="n">dt</span> <span class="o">=</span> <span class="mf">0.002</span>
<span class="n">trials_train</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">trials_test</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Fixed model parameters</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">ens_kwargs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>  <span class="c1"># neuron parameters</span>
    <span class="n">n_neurons</span><span class="o">=</span><span class="n">n</span><span class="p">,</span>
    <span class="n">dimensions</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">neuron_type</span><span class="o">=</span><span class="n">nengo</span><span class="o">.</span><span class="n">LIF</span><span class="p">(),</span>  <span class="c1"># nengolib.neurons.Tanh()</span>
    <span class="n">intercepts</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">n</span><span class="p">,</span>  <span class="c1"># intercepts are irelevant for Tanh</span>
    <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Hyper-parameters</span>
<span class="n">tau</span> <span class="o">=</span> <span class="mf">0.1</span>                   <span class="c1"># lowpass time-constant (10ms in [1])</span>
<span class="n">tau_learn</span> <span class="o">=</span> <span class="mf">0.1</span>             <span class="c1"># filter for error / learning (needed for spiking)</span>
<span class="n">tau_probe</span> <span class="o">=</span> <span class="mf">0.05</span>            <span class="c1"># filter for readout (needed for spiking</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>         <span class="c1"># 1 in [1]</span>
<span class="n">g</span> <span class="o">=</span> <span class="mf">1.5</span> <span class="o">/</span> <span class="mi">400</span>               <span class="c1"># 1.5 in [1], scaled by firing rates</span>
<span class="n">g_in</span> <span class="o">=</span> <span class="n">tau</span> <span class="o">/</span> <span class="n">amplitude</span>      <span class="c1"># scale the input encoders (usually 1)</span>
<span class="n">g_out</span> <span class="o">=</span> <span class="mf">1.0</span>                 <span class="c1"># scale the recurrent encoders (usually 1)</span>

<span class="c1"># Pre-computed constants</span>
<span class="n">T_train</span> <span class="o">=</span> <span class="n">trials_train</span> <span class="o">*</span> <span class="n">pulse_interval</span>
<span class="n">T_total</span> <span class="o">=</span> <span class="p">(</span><span class="n">trials_train</span> <span class="o">+</span> <span class="n">trials_test</span><span class="p">)</span> <span class="o">*</span> <span class="n">pulse_interval</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">Network</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
    <span class="c1"># Input is a pulse every pulse_interval seconds</span>
    <span class="n">U</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">pulse_interval</span> <span class="o">/</span> <span class="n">dt</span><span class="p">))</span>
    <span class="n">U</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">amplitude</span> <span class="o">/</span> <span class="n">dt</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">output</span><span class="o">=</span><span class="n">nengo</span><span class="o">.</span><span class="n">processes</span><span class="o">.</span><span class="n">PresentInput</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">dt</span><span class="p">))</span>

    <span class="c1"># Desired output is a decaying oscillator</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">size_in</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="n">nengolib</span><span class="o">.</span><span class="n">synapses</span><span class="o">.</span><span class="n">Bandpass</span><span class="p">(</span><span class="n">freq</span><span class="p">,</span> <span class="n">decay</span><span class="p">))</span>

<span class="c1"># Initial weights</span>
<span class="n">e_in</span> <span class="o">=</span> <span class="n">g_in</span> <span class="o">*</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># fixed encoders for f_in (u_in)</span>
<span class="n">e_out</span> <span class="o">=</span> <span class="n">g_out</span> <span class="o">*</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># fixed encoders for f_out (u)</span>
<span class="n">JD</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">g</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>  <span class="c1"># target-generating weights (variance g^2/n)</span>
</pre></div>
</div>
</div>
<div class="section" id="Classic-FORCE">
<h2>Classic FORCE<a class="headerlink" href="#Classic-FORCE" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">xC</span></code> are the neurons</li>
<li><code class="docutils literal"><span class="pre">sC</span></code> are the unfiltered currents into each neuron (<code class="docutils literal"><span class="pre">sC</span> <span class="pre">-&gt;</span> <span class="pre">Lowpass(tau)</span> <span class="pre">-&gt;</span> <span class="pre">xC</span></code>)</li>
<li><code class="docutils literal"><span class="pre">zC</span></code> is the learned output estimate, decoded by the neurons, and re-encoded back into <code class="docutils literal"><span class="pre">sC</span></code> alongside some random feedback (<code class="docutils literal"><span class="pre">JD</span></code>)</li>
<li><code class="docutils literal"><span class="pre">eC</span></code> is a gated error signal for RLS that turns off after <code class="docutils literal"><span class="pre">T_train</span></code> seconds. This error signal learns the feedback decoders by minmizing the difference between <code class="docutils literal"><span class="pre">z</span></code> (ideal output) and <code class="docutils literal"><span class="pre">zC</span></code> (actual output).</li>
</ul>
<p>The error signal driving RLS has an additional filter applied (<code class="docutils literal"><span class="pre">tau_learn</span></code>) to handle the case when this signal consists of spikes (not rates).</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">xC</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">(</span><span class="o">**</span><span class="n">ens_kwargs</span><span class="p">)</span>
    <span class="n">sC</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">size_in</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>  <span class="c1"># pre filter</span>
    <span class="n">eC</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">size_in</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="n">e</span> <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T_train</span> <span class="k">else</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">zC</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">size_in</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># learned output</span>

    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">sC</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">e_in</span><span class="p">)</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">sC</span><span class="p">,</span> <span class="n">xC</span><span class="o">.</span><span class="n">neurons</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="n">tau</span><span class="p">)</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">xC</span><span class="o">.</span><span class="n">neurons</span><span class="p">,</span> <span class="n">sC</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">JD</span><span class="p">)</span>  <span class="c1"># chaos</span>
    <span class="n">connC</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span>
        <span class="n">xC</span><span class="o">.</span><span class="n">neurons</span><span class="p">,</span> <span class="n">zC</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">)),</span>
        <span class="n">learning_rule_type</span><span class="o">=</span><span class="n">RLS</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">pre_synapse</span><span class="o">=</span><span class="n">tau_learn</span><span class="p">))</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">zC</span><span class="p">,</span> <span class="n">sC</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">e_out</span><span class="p">)</span>

    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">zC</span><span class="p">,</span> <span class="n">eC</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># actual</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">eC</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># ideal</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">eC</span><span class="p">,</span> <span class="n">connC</span><span class="o">.</span><span class="n">learning_rule</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="n">tau_learn</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="full-FORCE">
<h2>full-FORCE<a class="headerlink" href="#full-FORCE" title="Permalink to this headline">¶</a></h2>
<p><img alt="full-FORCE Figure 1" src="http://journals.plos.org/plosone/article/figure/image?size=large&amp;id=info:doi/10.1371/journal.pone.0191527.g001" /></p>
<div align="center"><p>Figure 1. Network architecture from [1].</p>
</div><div class="section" id="Target-Generating-Network">
<h3>Target-Generating Network<a class="headerlink" href="#Target-Generating-Network" title="Permalink to this headline">¶</a></h3>
<p>See Fig 1b.</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">xD</span></code> are the neurons that behave like classic FORCE in the ideal case (assuming the ideal output <code class="docutils literal"><span class="pre">z</span></code> is perfectly re-encoded)</li>
<li><code class="docutils literal"><span class="pre">sD</span></code> are the unfiltered currents into each neuron (<code class="docutils literal"><span class="pre">sD</span> <span class="pre">-&gt;</span> <span class="pre">Lowpass(tau)</span> <span class="pre">-&gt;</span> <span class="pre">xD</span></code>)</li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">xD</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">(</span><span class="o">**</span><span class="n">ens_kwargs</span><span class="p">)</span>
    <span class="n">sD</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">size_in</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>  <span class="c1"># pre filter</span>

    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">sD</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">e_in</span><span class="p">)</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">sD</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">e_out</span><span class="p">)</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">sD</span><span class="p">,</span> <span class="n">xD</span><span class="o">.</span><span class="n">neurons</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="n">tau</span><span class="p">)</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">xD</span><span class="o">.</span><span class="n">neurons</span><span class="p">,</span> <span class="n">sD</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">JD</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Task-Performing-Network">
<h3>Task-Performing Network<a class="headerlink" href="#Task-Performing-Network" title="Permalink to this headline">¶</a></h3>
<p>See Fig 1a.</p>
<ul class="simple">
<li><code class="docutils literal"><span class="pre">xF</span></code> are the neurons</li>
<li><code class="docutils literal"><span class="pre">sF</span></code> are the unfiltered currents into each neuron (<code class="docutils literal"><span class="pre">sF</span> <span class="pre">-&gt;</span> <span class="pre">Lowpass(tau)</span> <span class="pre">-&gt;</span> <span class="pre">xF</span></code>)</li>
<li><code class="docutils literal"><span class="pre">eF</span></code> is a gated error signal for RLS that turns off after <code class="docutils literal"><span class="pre">T_train</span></code> seconds. This error signal learns the full-rank feedback weights by minimizing the difference between the unfiltered currents <code class="docutils literal"><span class="pre">sD</span></code> and <code class="docutils literal"><span class="pre">sF</span></code>.</li>
</ul>
<p>The error signal driving RLS also has the same filter applied (<code class="docutils literal"><span class="pre">tau_learn</span></code>) to handle spikes. The output estimate is trained offline from the entire training set using batched least-squares, since this gives the best performance.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">xF</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Ensemble</span><span class="p">(</span><span class="o">**</span><span class="n">ens_kwargs</span><span class="p">)</span>
    <span class="n">sF</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">size_in</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>  <span class="c1"># pre filter</span>
    <span class="n">eF</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Node</span><span class="p">(</span><span class="n">size_in</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="k">lambda</span> <span class="n">t</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span> <span class="n">e</span> <span class="k">if</span> <span class="n">t</span> <span class="o">&lt;</span> <span class="n">T_train</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">e</span><span class="p">))</span>

    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">sF</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">e_in</span><span class="p">)</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">sF</span><span class="p">,</span> <span class="n">xF</span><span class="o">.</span><span class="n">neurons</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="n">tau</span><span class="p">)</span>
    <span class="n">connF</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span>
        <span class="n">xF</span><span class="o">.</span><span class="n">neurons</span><span class="p">,</span> <span class="n">sF</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)),</span>
        <span class="n">learning_rule_type</span><span class="o">=</span><span class="n">RLS</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">pre_synapse</span><span class="o">=</span><span class="n">tau_learn</span><span class="p">))</span>

    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">sF</span><span class="p">,</span> <span class="n">eF</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>  <span class="c1"># actual</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">sD</span><span class="p">,</span> <span class="n">eF</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">transform</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># ideal</span>
    <span class="n">nengo</span><span class="o">.</span><span class="n">Connection</span><span class="p">(</span><span class="n">eF</span><span class="p">,</span> <span class="n">connF</span><span class="o">.</span><span class="n">learning_rule</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="n">tau_learn</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="Results">
<h2>Results<a class="headerlink" href="#Results" title="Permalink to this headline">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="c1"># Probes</span>
    <span class="n">p_z</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="n">tau_probe</span><span class="p">)</span>
    <span class="n">p_zC</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">zC</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="n">tau_probe</span><span class="p">)</span>
    <span class="n">p_xF</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Probe</span><span class="p">(</span><span class="n">xF</span><span class="o">.</span><span class="n">neurons</span><span class="p">,</span> <span class="n">synapse</span><span class="o">=</span><span class="n">tau_probe</span><span class="p">)</span>

<span class="k">with</span> <span class="n">nengo</span><span class="o">.</span><span class="n">Simulator</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">dt</span><span class="o">=</span><span class="n">dt</span><span class="p">)</span> <span class="k">as</span> <span class="n">sim</span><span class="p">:</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">T_total</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/arvoelke/CTN/nengo/nengo/utils/numpy.py:79: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.
  v = a[inds]
/home/arvoelke/CTN/nengolib/nengolib/signal/system.py:197: UserWarning: y0 (None!=0) does not properly initialize the system; see Nengo issue #1124.
  &#34;Nengo issue #1124.&#34; % y0, UserWarning)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<div id="fb11a283-01cd-4d4e-94d4-71ef842eaa20" style="
    width: 100%;
    border: 1px solid #cfcfcf;
    border-radius: 4px;
    text-align: center;
    position: relative;">
  <div class="pb-text" style="
      position: absolute;
      width: 100%;">
    0%
  </div>
  <div class="pb-fill" style="
      background-color: #bdd2e6;
      width: 0%;">
    <style type="text/css" scoped="scoped">
        @keyframes pb-fill-anim {
            0% { background-position: 0 0; }
            100% { background-position: 100px 0; }
        }
    </style>
    &nbsp;
  </div>
</div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div></div>
<script type="text/javascript">
var element = document.currentScript.previousSibling.previousSibling;

              (function () {
                  var root = document.getElementById('fb11a283-01cd-4d4e-94d4-71ef842eaa20');
                  var text = root.getElementsByClassName('pb-text')[0];
                  var fill = root.getElementsByClassName('pb-fill')[0];

                  text.innerHTML = 'Build finished in 0:00:01.';

            fill.style.width = '100%';
            fill.style.animation = 'pb-fill-anim 2s linear infinite';
            fill.style.backgroundSize = '100px 100%';
            fill.style.backgroundImage = 'repeating-linear-gradient(' +
                '90deg, #bdd2e6, #edf2f8 40%, #bdd2e6 80%, #bdd2e6)';


                fill.style.animation = 'none';
                fill.style.backgroundImage = 'none';

              })();

</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/home/arvoelke/CTN/nengolib/nengolib/signal/system.py:197: UserWarning: y0 (None!=0) does not properly initialize the system; see Nengo issue #1124.
  &#34;Nengo issue #1124.&#34; % y0, UserWarning)
/home/arvoelke/CTN/nengolib/nengolib/signal/system.py:197: UserWarning: y0 (None!=0) does not properly initialize the system; see Nengo issue #1124.
  &#34;Nengo issue #1124.&#34; % y0, UserWarning)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<div id="4d2cd222-5979-4f75-9022-42c8e2549cc4" style="
    width: 100%;
    border: 1px solid #cfcfcf;
    border-radius: 4px;
    text-align: center;
    position: relative;">
  <div class="pb-text" style="
      position: absolute;
      width: 100%;">
    0%
  </div>
  <div class="pb-fill" style="
      background-color: #bdd2e6;
      width: 0%;">
    <style type="text/css" scoped="scoped">
        @keyframes pb-fill-anim {
            0% { background-position: 0 0; }
            100% { background-position: 100px 0; }
        }
    </style>
    &nbsp;
  </div>
</div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div></div>
<script type="text/javascript">
var element = document.currentScript.previousSibling.previousSibling;

              (function () {
                  var root = document.getElementById('4d2cd222-5979-4f75-9022-42c8e2549cc4');
                  var text = root.getElementsByClassName('pb-text')[0];
                  var fill = root.getElementsByClassName('pb-fill')[0];

                  text.innerHTML = 'Simulation finished in 0:00:05.';

            if (100.0 > 0.) {
                fill.style.transition = 'width 0.1s linear';
            } else {
                fill.style.transition = 'none';
            }

            fill.style.width = '100.0%';
            fill.style.animation = 'none';
            fill.style.backgroundImage = 'none'


                fill.style.animation = 'none';
                fill.style.backgroundImage = 'none';

              })();

</script></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="c1"># We do the readout training for full-FORCE offline, since this gives better</span>
<span class="c1"># performance without affecting anything else</span>
<span class="n">t_train</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">T_train</span>
<span class="n">t_test</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">()</span> <span class="o">&gt;=</span> <span class="n">T_train</span>

<span class="n">solver</span> <span class="o">=</span> <span class="n">nengo</span><span class="o">.</span><span class="n">solvers</span><span class="o">.</span><span class="n">LstsqL2</span><span class="p">(</span><span class="n">reg</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
<span class="n">wF</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">solver</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">p_xF</span><span class="p">][</span><span class="n">t_train</span><span class="p">],</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">p_z</span><span class="p">][</span><span class="n">t_train</span><span class="p">])</span>
<span class="n">zF</span> <span class="o">=</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">p_xF</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">wF</span><span class="p">)</span>

<span class="n">pylab</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Training Output&quot;</span><span class="p">)</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">()[</span><span class="n">t_train</span><span class="p">],</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">p_zC</span><span class="p">][</span><span class="n">t_train</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;classic-FORCE&quot;</span><span class="p">)</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">()[</span><span class="n">t_train</span><span class="p">],</span> <span class="n">zF</span><span class="p">[</span><span class="n">t_train</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;full-FORCE&quot;</span><span class="p">)</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">()[</span><span class="n">t_train</span><span class="p">],</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">p_z</span><span class="p">][</span><span class="n">t_train</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ideal&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time (s)&quot;</span><span class="p">)</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Output&quot;</span><span class="p">)</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">pylab</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Testing Error&quot;</span><span class="p">)</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">()[</span><span class="n">t_test</span><span class="p">],</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">p_zC</span><span class="p">][</span><span class="n">t_test</span><span class="p">]</span> <span class="o">-</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">p_z</span><span class="p">][</span><span class="n">t_test</span><span class="p">],</span>
           <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;classic-FORCE&quot;</span><span class="p">)</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">trange</span><span class="p">()[</span><span class="n">t_test</span><span class="p">],</span> <span class="n">zF</span><span class="p">[</span><span class="n">t_test</span><span class="p">]</span> <span class="o">-</span> <span class="n">sim</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">p_z</span><span class="p">][</span><span class="n">t_test</span><span class="p">],</span>
           <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;full-FORCE&quot;</span><span class="p">)</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time (s)&quot;</span><span class="p">)</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Error&quot;</span><span class="p">)</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">pylab</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_examples_full_force_learning_12_0.png" src="../../_images/notebooks_examples_full_force_learning_12_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/notebooks_examples_full_force_learning_12_1.png" src="../../_images/notebooks_examples_full_force_learning_12_1.png" />
</div>
</div>
</div>
<div class="section" id="References">
<h2>References<a class="headerlink" href="#References" title="Permalink to this headline">¶</a></h2>
<p>[1] DePasquale, B., Cueva, C. J., Rajan, K., &amp; Abbott, L. F. (2018). full-FORCE: A target-based method for training recurrent networks. PloS one, 13(2), e0191527. <a class="reference external" href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0191527">http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0191527</a></p>
<p>[2] Sussillo, D., &amp; Abbott, L. F. (2009). Generating coherent patterns of activity from chaotic neural networks. Neuron, 63(4), 544-557. <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2756108/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2756108/</a></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../../index.html">
    <img class="logo" src="../../_static/logo.png" alt="Logo"/>
    
    <h1 class="logo logo-name">nengolib</h1>
    
  </a>
</p>



<p class="blurb">Tools for robust dynamics in Nengo.</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=arvoelke&repo=nengolib&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





    

<p>
<a class="badge" href="https://travis-ci.org/arvoelke/nengolib">
    <img
        alt="https://secure.travis-ci.org/arvoelke/nengolib.svg?branch=master"
        src="https://secure.travis-ci.org/arvoelke/nengolib.svg?branch=master"
    />
</a>
</p>




    

<p>
<a class="badge" href="https://codecov.io/github/arvoelke/nengolib">
    <img
    alt="https://codecov.io/github/arvoelke/nengolib/coverage.svg?branch=master"
    src="https://codecov.io/github/arvoelke/nengolib/coverage.svg?branch=master"
    />
</a>
</p>
<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../notebooks.html">Notebooks</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../notebooks.examples.html">Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../notebooks.research.html">Research</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../reference.html">Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../success.html">Success stories</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../license.html">License</a></li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script><div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../../notebooks.html">Notebooks</a><ul>
  <li><a href="../../notebooks.examples.html">Examples</a><ul>
      <li>Previous: <a href="../../notebooks.examples.html" title="previous chapter">Examples</a></li>
      <li>Next: <a href="hetero_synapse.html" title="next chapter">Heterogeneous Synapses</a></li>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2017-2018, Aaron Voelker.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.6.7</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../_sources/notebooks/examples/full_force_learning.ipynb.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>